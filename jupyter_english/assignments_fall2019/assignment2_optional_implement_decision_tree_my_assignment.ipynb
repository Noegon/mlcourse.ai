{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \n",
    "Author: [Yury Kashnitsky](https://yorko.github.io) (@yorko). Edited by Anna Tarelina (@feuerengel). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment #2. Optional part\n",
    "## <center> Implementation of the decision tree algorithm\n",
    "    \n",
    "#  <center>  <font color = 'red'> Warning! </font>This is a very useful but ungraded assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as scipy_stats\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix `random_state` (a.k.a. random seed) beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Implement the class `DecisionTree`**\n",
    "**Specification:**\n",
    "- the class is inherited from `sklearn.BaseEstimator`;\n",
    "- class constructor has the following parameters: \n",
    "    `max_depth` - maximum depth of the tree (`numpy.inf` by default); \n",
    "    `min_samples_split` - the minimum number of instances in a node for a splitting to be done (2 by default); \n",
    "    `criterion` - split criterion ('gini' or 'entropy' for classification, 'variance' or 'mad_median' for regression; 'gini' by default);\n",
    "    \n",
    "    A functional to be maximized to find an optimal partition at a given node has the form\n",
    "    $$Q(X, j, t) = F(X) - \\dfrac{|X_l|}{|X|} F(X_l) - \\dfrac{|X_r|}{|X|} F(X_r),$$\n",
    "    where $X$ are samples at a given node, $X_l$ and $X_r$ are partitions of samples $X$ into two parts \n",
    "    with the following condition $[x_j < t]$, and $F(X)$ is a partition criterion.\n",
    "    \n",
    "    For classification: let $p_i$ be the fraction of the instances of the $i$-th class in the dataset $X$.\n",
    "    \n",
    "    'gini': Gini impurity $F(X) = 1 -\\sum_{i = 1}^K p_i^2$.\n",
    "    \n",
    "    'entropy': Entropy $F(X) = -\\sum_{i = 1}^K p_i \\log_2(p_i)$.\n",
    "    \n",
    "    For regression: $y_j = y(x_j)$ - is a target for an instance $x_j$, $y = (y_1, \\dots, y_{|X|})$ - is a target vector.\n",
    "    \n",
    "    'variance': Variance (mean quadratic deviation from average) $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}(y_j - \\dfrac{1}{|X|}\\sum_{x_i \\in X}y_i)^2$\n",
    "    \n",
    "    'mad_median': Mean deviation from the median $F(X) = \\dfrac{1}{|X|} \\sum_{x_j \\in X}|y_j - \\mathrm{med}(y)|$\n",
    "    \n",
    "- the class has several methods: `fit`, `predict` and `predict_proba`;\n",
    "- the`fit` method takes the matrix of instances `X` and a target vector `y` (`numpy.ndarray` objects) and returns an instance of the class `DecisionTree` representing the decision tree trained on the dataset `(X, y)` according to parameters set in the constructor; \n",
    "- the `predict_proba` method takes the matrix of instances `X` and returns the matrix `P` of a size `X.shape[0] x K`, where `K` is the number of classes and $p_{ij}$ is the probability of an instance in $i$-th row of `X` to belong to class $j \\in \\{1, \\dots, K\\}$.\n",
    "- the `predict` method takes the matrix of instances `X` and returns a prediction vector; in case of classification, prediction for an instance $x_i$ falling into leaf $L$ will be the class, mostly represented among instances in $L$. In case of regression, it'll be the mean value of targets for all instances in leaf $L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_distr_dict(array):\n",
    "    arr = np.array(array, dtype=int)\n",
    "    arr.flatten()\n",
    "    arr.sort()\n",
    "    countedElements = Counter(arr)\n",
    "    uniqueElements = list(dict.fromkeys(arr))\n",
    "    uniqueElements.sort()\n",
    "    prob_dict = {}\n",
    "    elements_len = len(arr)\n",
    "\n",
    "    for key in uniqueElements:\n",
    "        prob_dict[key] = countedElements[key] / elements_len\n",
    "    return prob_dict\n",
    "\n",
    "def entropy(y):\n",
    "    prob_dict = probability_distr_dict(array=y)\n",
    "    \n",
    "    result = 0\n",
    "    for key in prob_dict:\n",
    "        result += prob_dict[key] * np.log2(prob_dict[key])\n",
    "    return -1 * result if result != 0 else 0.0\n",
    "\n",
    "def gini(y):\n",
    "    prob_dict = probability_distr_dict(array=y)\n",
    "    \n",
    "    result = 0\n",
    "    for key in prob_dict:\n",
    "        result += prob_dict[key]**2\n",
    "    return 1 - result\n",
    "\n",
    "def variance(y):\n",
    "    arr = np.array(y, dtype=int)\n",
    "    arr.flatten()\n",
    "    a = [(x - (np.sum(arr) / len(arr)))**2 for x in arr]\n",
    "    result = np.sum(a) / len(a)\n",
    "    return result\n",
    "\n",
    "def mad_median(y):\n",
    "    arr = np.array(y, dtype=int)\n",
    "    arr.flatten()\n",
    "    a = [(x - np.median(arr)) for x in arr]\n",
    "    result = np.sum(a) / len(a)\n",
    "    return result\n",
    "\n",
    "def best_partition_functional_result(X, y, idx_to_check=[], F=gini):\n",
    "    current_start_index = 0\n",
    "    left_split = []\n",
    "    right_split = []\n",
    "    maximization_parameter = 0\n",
    "    intermediate_param = None\n",
    "    split_index = 0\n",
    "    indicies = idx_to_check if len(idx_to_check) != 0 else range(current_start_index, len(X))\n",
    "#     indicies = range(current_start_index, len(X))\n",
    "    print('indicies to check: ' + str(indicies))\n",
    "    for i in indicies:\n",
    "        current_left_split = y[0:i]\n",
    "        current_right_split = y[i:len(y)]\n",
    "        current_maximization_parameter = partition_functional_result(y,\n",
    "                                                                     current_left_split,\n",
    "                                                                     current_right_split,\n",
    "                                                                     F)\n",
    "        if maximization_parameter < current_maximization_parameter:\n",
    "            left_split = current_left_split\n",
    "            right_split = current_right_split\n",
    "            maximization_parameter = current_maximization_parameter\n",
    "            print('current index: ' + str(i))\n",
    "            print('current param: ' + str(y[i]))\n",
    "            intermediate_param = y[i] if i == 0 else (y[i-1] + y[i]) / 2\n",
    "            split_index = i\n",
    "        current_start_index += 1\n",
    "    return (left_split,\n",
    "            right_split,\n",
    "            X[0:len(left_split)],\n",
    "            X[len(left_split):len(y)],\n",
    "            F(left_split),\n",
    "            F(right_split),\n",
    "            F(y),\n",
    "            intermediate_param,\n",
    "            split_index)\n",
    "\n",
    "def partition_functional_result(X, X_l, X_r, F=gini):\n",
    "    return F(X) - (len(X_l) / len(X)) * F(X_r) - (len(X_r) / len(X)) * F(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Node` class implements a node in the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, feature_idx=0, threshold=0, labels=None, left=None, right=None):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.threshold = threshold\n",
    "        self.labels = labels\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "       \n",
    "    def __str__():\n",
    "        print(\"feature idx: \" + str(feature_idx))\n",
    "        print(\"labels: \" + str(feature_idx))\n",
    "        print(\"left: \\n\" + str(left))\n",
    "        print(\"right: \\n\" + str(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\n",
      "indicies to check: [2, 4, 9, 11, 12, 13, 16]\n",
      "current index: 4\n",
      "current param: 1\n",
      "current index: 9\n",
      "current param: 1\n",
      "current index: 16\n",
      "current param: 0\n",
      "indicies to check: [2, 3, 5, 9, 10, 13, 19]\n",
      "current index: 9\n",
      "current param: 1\n",
      "current index: 13\n",
      "current param: 0\n",
      "current index: 19\n",
      "current param: 1\n",
      "indicies to check: [2, 6, 7, 8, 9, 10, 11, 16]\n",
      "current index: 2\n",
      "current param: 1\n",
      "current index: 16\n",
      "current param: 0\n",
      "X_left\n",
      "    is_orange  x2  x3\n",
      "0           0  11  31\n",
      "17          0  10  12\n",
      "2           0  14  31\n",
      "3           0  12  31\n",
      "15          0  23  12\n",
      "6           0  11  31\n",
      "14          0  22  12\n",
      "8           0  11  31\n",
      "13          0  25  12\n",
      "12          0  21  12\n",
      "11          0  11  12\n",
      "16          1  26  22\n",
      "9           1  11  31\n",
      "18          1  31  12\n",
      "7           1  15  31\n",
      "5           1  31  31\n",
      "X_right\n",
      "    is_orange  x2  x3\n",
      "4           1  13  22\n",
      "1           1  17  12\n",
      "10          1  17  31\n",
      "19          1  31  12\n",
      "Y_left\n",
      "    result\n",
      "0        0\n",
      "17       0\n",
      "2        1\n",
      "3        1\n",
      "15       0\n",
      "6        0\n",
      "14       0\n",
      "8        0\n",
      "13       0\n",
      "12       1\n",
      "11       1\n",
      "16       0\n",
      "9        1\n",
      "18       0\n",
      "7        0\n",
      "5        0\n",
      "Y_right\n",
      "    result\n",
      "4        1\n",
      "1        1\n",
      "10       1\n",
      "19       1\n",
      "iteration: 2\n",
      "indicies to check: [2, 4, 9, 11, 12, 13]\n",
      "current index: 4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-721812205ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m# df_4.iloc[0:5, len(df_4.columns) - 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# df_2.sort_values('is_orange').iloc[0:5]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0m__build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_orange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-253-721812205ec8>\u001b[0m in \u001b[0;36m__build\u001b[0;34m(X_train, Y_train, current_criterion_value, iteration, Func)\u001b[0m\n\u001b[1;32m     96\u001b[0m                          \u001b[0mcurrent_criterion_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                          \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                          Func=Func)\n\u001b[0m\u001b[1;32m     99\u001b[0m         t.right = __build(X_right,\n\u001b[1;32m    100\u001b[0m                           \u001b[0mY_right\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-253-721812205ec8>\u001b[0m in \u001b[0;36m__build\u001b[0;34m(X_train, Y_train, current_criterion_value, iteration, Func)\u001b[0m\n\u001b[1;32m     55\u001b[0m                                                            \u001b[0msorted_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                                                            \u001b[0midx_to_check\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                                                            F=Func)\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mmean_gain_paramter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpart_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpart_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmean_gain_paramter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-250-4123af85075e>\u001b[0m in \u001b[0;36mbest_partition_functional_result\u001b[0;34m(X, y, idx_to_check, F)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mmaximization_parameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_maximization_parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'current index: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'current param: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mintermediate_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0msplit_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "arr_y = np.array([0,1,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,0,0,1])\n",
    "\n",
    "arr_1 = np.array([0,1,0,0,1,1,0,1,0,1,1,0,0,0,0,0,1,0,1,1], dtype=int)\n",
    "arr_2 = np.array([11,17,14,12,13,31,11,15,11,11,17,11,21,25,22,23,26,10,31,31], dtype=int)\n",
    "arr_3 = np.array([31,12,31,31,22,31,31,31,31,31,31,12,12,12,12,12,22,12,12,12], dtype=int)\n",
    "\n",
    "df_common = pd.DataFrame(np.transpose([arr_1, arr_2, arr_3, arr_y]), columns=['is_orange', 'x2', 'x3', 'result'])\n",
    "columns = df_common.columns\n",
    "\n",
    "# print(df_common.sort_values(columns[1]))\n",
    "\n",
    "max_depth = 5\n",
    "iteration = 0\n",
    "def __build(X_train=pd.DataFrame(),\n",
    "            Y_train=pd.DataFrame(),\n",
    "            current_criterion_value=None,\n",
    "            iteration=0,\n",
    "            Func=gini):\n",
    "    \n",
    "    # root node\n",
    "    t = Node(feature_idx=0,\n",
    "             threshold=0,\n",
    "             labels=None,\n",
    "             left=None,\n",
    "             right=None)\n",
    "    \n",
    "    best_params = None\n",
    "    \n",
    "    if current_criterion_value != None and (current_criterion_value <= 0.01 or iteration >= max_depth):\n",
    "        return t\n",
    "    else:\n",
    "        iteration += 1\n",
    "        print(\"iteration: \" + str(iteration))\n",
    "        for column in X_train.columns:\n",
    "            current_feature = X_train[column]\n",
    "            frame = { column: current_feature, Y_train.columns[0]: Y_train[Y_train.columns[0]] } \n",
    "            combined_feature = pd.DataFrame(frame) \n",
    "            sorted_feature = combined_feature.sort_values(column)\n",
    "            previous_result = sorted_feature.iloc[0][Y_train.columns[0]]\n",
    "\n",
    "            current_result = None\n",
    "            idx_to_check = []\n",
    "\n",
    "            for index in range(1, len(sorted_feature)):\n",
    "                current_result = sorted_feature.iloc[index][Y_train.columns[0]]\n",
    "                if current_result != previous_result:\n",
    "                    idx_to_check.append(index)\n",
    "                previous_result = current_result\n",
    "\n",
    "#             print(idx_to_check)\n",
    "            if len(idx_to_check) == 0:\n",
    "                break\n",
    "            # calculate entropy gain or giny impyty reduction for current feature\n",
    "            part_result = best_partition_functional_result(sorted_feature[column],\n",
    "                                                           sorted_feature[Y_train.columns[0]],\n",
    "                                                           idx_to_check,\n",
    "                                                           F=Func)\n",
    "            mean_gain_paramter = (part_result[4] + part_result[5]) / 2\n",
    "            if best_params == None or (best_params[4] + best_params[5]) / 2 > mean_gain_paramter:\n",
    "                best_params = part_result\n",
    "                \n",
    "                t.feature_idx = X_train.columns.get_loc(column)\n",
    "                t.labels = [column]\n",
    "            \n",
    "#             print(np.array(part_result[0]))\n",
    "#             print(np.array(part_result[1]))\n",
    "#             print(np.array(part_result[2]))\n",
    "#             print(np.array(part_result[3]))\n",
    "#             print(part_result[4])\n",
    "#             print(part_result[5])\n",
    "#             print(part_result[6])\n",
    "#             print(part_result[7])\n",
    "#             print(part_result[8])\n",
    "#             print('----------+++++----------')\n",
    "        \n",
    "        combined_data_set = pd.concat([X_train, Y_train], axis=1, sort=False)\n",
    "        combined_data_set.sort_values(t.labels[0], inplace=True)\n",
    "        \n",
    "        t.threshold = best_params[7]\n",
    "        X_left = combined_data_set.iloc[0:best_params[8], np.arange(0, len(X_train.columns))]\n",
    "        X_right = combined_data_set.iloc[best_params[8]:len(combined_data_set),\n",
    "                                         np.arange(0, len(X_train.columns))]\n",
    "        Y_left = pd.DataFrame(combined_data_set.iloc[0:best_params[8], len(X_train.columns)])\n",
    "        Y_right = pd.DataFrame(combined_data_set.iloc[best_params[8]:len(combined_data_set),\n",
    "                                                      len(X_train.columns)])\n",
    "        print(\"X_left\")\n",
    "        print(X_left)\n",
    "        print(\"X_right\")\n",
    "        print(X_right)\n",
    "        print(\"Y_left\")\n",
    "        print(Y_left)\n",
    "        print('Y_right')\n",
    "        print(Y_right)\n",
    "        t.left = __build(X_left,\n",
    "                         Y_left,\n",
    "                         current_criterion_value=(best_params[4] + best_params[5]) / 2,\n",
    "                         iteration=iteration,\n",
    "                         Func=Func)\n",
    "        t.right = __build(X_right,\n",
    "                          Y_right,\n",
    "                          current_criterion_value=(best_params[4] + best_params[5]) / 2,\n",
    "                          iteration=iteration,\n",
    "                          Func=Func)\n",
    "    return t\n",
    "            \n",
    "#     if entropy(L) <= 0.01 || iteration >= max_depth:\n",
    "#         return t\n",
    "#     else:\n",
    "#         Find the best binary split L = L_left + L_right\n",
    "#         t.left = __build(X_left)\n",
    "#         t.right = __build(X_right)\n",
    "#         iteration += 1\n",
    "#     return t  \n",
    "\n",
    "# df_2 = df_common.drop(columns=['result'], axis=0)\n",
    "# df_3 = df_common.drop(columns=['is_orange', 'x2', 'x3'], axis=0)\n",
    "# df_4 = pd.concat([df_2, df_3], axis=1, sort=False)\n",
    "# df_4.iloc[0:5, np.arange(0,len(df_4.columns) - 1)]\n",
    "# df_4.iloc[0:5, len(df_4.columns) - 1]\n",
    "# df_2.sort_values('is_orange').iloc[0:5]\n",
    "__build(df_common.drop(columns=['result'], axis=0), df_common.drop(columns=['is_orange', 'x2', 'x3'], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's determine the function for calculating a prediction in a leaf. For regression, let's take the mean for all values in a leaf, for classification - the most popular class in leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Criterion(Enum):\n",
    "    ENTHROPY = 'enthropy'\n",
    "    GINI = 'gini'\n",
    "    VARIANCE = 'variance'\n",
    "    MAD_MEDIAN = 'mad_median'\n",
    "\n",
    "class DecisionTree(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, max_depth=np.inf, min_samples_split=2, \n",
    "                 criterion=Criterion.GINI, debug=False):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.debug = debug\n",
    "        self.primaryNode = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "#         create node t\n",
    "#         if the stopping criterion is True:\n",
    "#             assign a predictive model to t\n",
    "#         else:\n",
    "#             Find the best binary split L = L_left + L_right\n",
    "#             t.left = build(L_left)\n",
    "#             t.right = build(L_right)\n",
    "#         return t \n",
    "\n",
    "    def predict(self, X):\n",
    "        pass \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the implemented algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset `digits` using the method `load_digits`. Split the data into train and test with the `train_test_split` method, use parameter values `test_size=0.2`, and `random_state=17`. Try to train shallow decision trees and make sure that gini and entropy criteria return different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 5-folds cross-validation (`GridSearchCV`) pick up the optimal values of the `max_depth` and `criterion` parameters. For the parameter `max_depth` use range(3, 11), for criterion use {'gini', 'entropy'}. Quality measure is `scoring`='accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the plot of the mean quality measure `accuracy` for criteria `gini` and `entropy` depending on `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Choose all correct statements:**\n",
    "1. Optimal value of the `max_depth` parameter is on the interval [4, 9] for both criteria.\n",
    "2. Created plots have no intersection on the interval [3, 10]\n",
    "3. Created plots intersect each other only once on the interval [3, 10].\n",
    "4. The best quality for `max_depth` on the interval [3, 10] is reached using `gini` criterion .\n",
    "5. Accuracy is strictly increasing at least for one of the criteria, when `max_depth` is also increasing on the interval [3, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What are the optimal values for max_depth and criterion parameters?**\n",
    "1. max_depth = 7, criterion = 'gini';\n",
    "2. max_depth = 7, criterion = 'entropy';\n",
    "3. max_depth = 10, criterion = 'entropy';\n",
    "4. max_depth = 10, criterion = 'gini';\n",
    "5. max_depth = 9, criterion = 'entropy';\n",
    "6. max_depth = 9, criterion = 'gini';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train decision tree on `(X_train, y_train)` using the optimal values of `max_depth` and `criterion`. Compute class probabilities for `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the given matrix, compute the mean class probabilities for all instances in `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What is the maximum probability in a resulted vector?**\n",
    "1. 0.127\n",
    "2. 0.118\n",
    "3. 1.0\n",
    "4. 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset `boston` using the method `load_boston`. Split the data into train and test with the `train_test_split` method, use parameter values `test_size=0.2`, `random_state=17`. Try to train shallow regression decision trees and make sure that `variance` and `mad_median` criteria return different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 5-folds cross-validation (`GridSearchCV`) pick up the optimal values of the `max_depth` and `criterion` parameters. For the parameter `max_depth` use `range(2, 9)`, for `criterion` use {'variance', 'mad_median'}. Quality measure is `scoring`='neg_mean_squared_error'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the plot of the mean quality measure `neg_mean_squared_error` for criteria `variance` and `mad_median` depending on `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Choose all correct statements:**\n",
    "1. Created plots have no intersection on the interval [2, 8].\n",
    "2. Created plots intersect each other only once on the interval [2, 8].\n",
    "3. Optimal value of the `max_depth` for each of the criteria is on the border of the interval [2, 8].\n",
    "4. The best quality at `max_depth` on the interval [2, 8] is reached using `mad_median` criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. What are the optimal values for `max_depth` and `criterion` parameters?**\n",
    "1. max_depth = 9, criterion = 'variance';\n",
    "2. max_depth = 5, criterion = 'mad_median';\n",
    "3. max_depth = 4, criterion = 'variance';\n",
    "4. max_depth = 2, criterion = 'mad_median';\n",
    "5. max_depth = 4, criterion = 'mad_median';\n",
    "6. max_depth = 5, criterion = 'variance'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "lesson4_part2_Decision_trees.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
