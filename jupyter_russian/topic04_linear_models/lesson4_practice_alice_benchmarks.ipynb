{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 2\n",
    "</center>\n",
    "Автор материала: Юрий Исаков и Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 4. Линейные модели классификации и регрессии\n",
    "## <center>  Практика. Идентификация пользователя с помощью логистической регрессии\n",
    "\n",
    "Тут мы воспроизведем парочку бенчмарков нашего соревнования и вдохновимся побить третий бенчмарк, а также остальных участников. Веб-формы для отправки ответов тут не будет, ориентир – [leaderboard](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/leaderboard) соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка и преобразование данных\n",
    "Зарегистрируйтесь на [Kaggle](www.kaggle.com), если вы не сделали этого раньше, зайдите на [страницу](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнования и скачайте данные. Первым делом загрузим обучающую и тестовую выборки и посмотрим на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                         time5  ...               time6  site7  \\\n",
       "session_id                      ...                              \n",
       "21669                      NaT  ...                 NaT    NaN   \n",
       "54843                      NaT  ...                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ... 2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ... 2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ... 2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим обучающую и тестовую выборки\n",
    "train_df = pd.read_csv('../../data/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/train_sessions.csv',\n",
    "                       index_col='session_id',\n",
    "                       parse_dates=True)\n",
    "test_df = pd.read_csv('../../data/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/test_sessions.csv',\n",
    "                      index_col='session_id',\n",
    "                      parse_dates=True)\n",
    "\n",
    "# приведем колонки time1, ..., time10 к временному формату\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# отсортируем данные по времени\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# посмотрим на заголовок обучающей выборки\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82797 entries, 1 to 82797\n",
      "Data columns (total 20 columns):\n",
      "site1     82797 non-null int64\n",
      "time1     82797 non-null datetime64[ns]\n",
      "site2     81308 non-null float64\n",
      "time2     81308 non-null datetime64[ns]\n",
      "site3     80075 non-null float64\n",
      "time3     80075 non-null datetime64[ns]\n",
      "site4     79182 non-null float64\n",
      "time4     79182 non-null datetime64[ns]\n",
      "site5     78341 non-null float64\n",
      "time5     78341 non-null datetime64[ns]\n",
      "site6     77566 non-null float64\n",
      "time6     77566 non-null datetime64[ns]\n",
      "site7     76840 non-null float64\n",
      "time7     76840 non-null datetime64[ns]\n",
      "site8     76151 non-null float64\n",
      "time8     76151 non-null datetime64[ns]\n",
      "site9     75484 non-null float64\n",
      "time9     75484 non-null datetime64[ns]\n",
      "site10    74806 non-null float64\n",
      "time10    74806 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](10), float64(9), int64(1)\n",
      "memory usage: 13.3 MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82797, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающей выборке содержатся следующие признаки:\n",
    "    - site1 – индекс первого посещенного сайта в сессии\n",
    "    - time1 – время посещения первого сайта в сессии\n",
    "    - ...\n",
    "    - site10 – индекс 10-го посещенного сайта в сессии\n",
    "    - time10 – время посещения 10-го сайта в сессии\n",
    "    - target – целевая переменная, 1 для сессий Элис, 0 для сессий других пользователей\n",
    "    \n",
    "Сессии пользователей выделены таким образом, что они не могут быть длиннее получаса или 10 сайтов. То есть сессия считается оконченной либо когда пользователь посетил 10 сайтов подряд либо когда сессия заняла по времени более 30 минут.\n",
    "\n",
    "В таблице встречаются пропущенные значения, это значит, что сессия состоит менее, чем из 10 сайтов. Заменим пропущенные значения нулями и приведем признаки к целому типу. Также загрузим словарь сайтов и посмотрим, как он выглядит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего сайтов: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приведем колонки site1, ..., site10 к целочисленному формату и заменим пропуски нулями\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
    "\n",
    "# загрузим словарик сайтов\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# датафрейм словарика сайтов\n",
    "sites_dict_df = pd.DataFrame(list(site_dict.keys()), \n",
    "                          index=list(site_dict.values()), \n",
    "                          columns=['site'])\n",
    "print(u'всего сайтов:', sites_dict_df.shape[0])\n",
    "sites_dict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим целевую переменную и объединим выборки, чтобы вместе привести их к разреженному формату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наша целевая переменная\n",
    "y_train = train_df['target']\n",
    "\n",
    "# объединенная таблица исходных данных\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# индекс, по которому будем отделять обучающую выборку от тестовой\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для самой первой модели будем использовать только посещенные сайты в сессии (но не будем обращать внимание на временные признаки). За таким выбором данных для модели стоит такая идея:  *у Элис есть свои излюбленные сайты, и чем чаще вы видим эти сайты в сессии, тем выше вероятность, что это сессия Элис и наоборот.*\n",
    "\n",
    "Подготовим данные, из всей таблицы выберем только признаки `site1, site2, ... , site10`. Напомним, что пропущенные значения заменены нулем. Вот как выглядят первые строки таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# табличка с индексами посещенных сайтов в сессии\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сессии представляют собой последовательность индексов сайтов и данные в таком виде неудобны для линейных методов. В соответствии с нашей гипотезой (у Элис есть излюбленные сайты) надо преобразовать эту таблицу таким образом, чтобы каждому возможному сайту соответствовал свой отдельный признак (колонка), а его значение равнялось бы количеству посещений этого сайта в сессии. Это делается в две строчки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csr_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# последовательность с индексами\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "# print(full_sites.values.flatten())\n",
    "\n",
    "# искомая матрица\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0] + 10, 10)))[:, 1:]\n",
    "# print(full_sites_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запишем тестовую и тренировочную выборки по сайтам в файлы\n",
    "train_df[sites].fillna(0).astype('int').to_csv('train_sessions_text.txt', \n",
    "                                               sep=' ', \n",
    "                       index=None, header=None)\n",
    "test_df[sites].fillna(0).astype('int').to_csv('test_sessions_text.txt', \n",
    "                                              sep=' ', \n",
    "                       index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 3), max_features=50000)\n",
    "with open('train_sessions_text.txt') as inp_train_file:\n",
    "    X_train = cv.fit_transform(inp_train_file)\n",
    "with open('test_sessions_text.txt') as inp_test_file:\n",
    "    X_test = cv.transform(inp_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train) # на выходе - разреженная матрица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 50000), (82797, 50000))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = full_sites_sparse[:idx_split]\n",
    "X_test_sparse = full_sites_sparse[idx_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48371), (253561,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82797, 48371)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один плюс использования разреженных матриц в том, что для них имеются специальные реализации как матричных операций, так и алгоритмов машинного обучения, что подчас позволяет ощутимо ускорить операции за счет особенностей структуры данных. Это касается и логистической регрессии. Вот теперь у нас все готово для построения нашей первой модели.\n",
    "\n",
    "### 2. Построение первой модели\n",
    "\n",
    "Итак, у нас есть алгоритм и данные для него, построим нашу первую модель, воспользовавшись релизацией [логистической регрессии](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) из пакета `sklearn` с параметрами по умолчанию. Первые 90% данных будем использовать для обучения (обучающая выборка отсортирована по времени), а оставшиеся 10% для проверки качества (validation). \n",
    "\n",
    "**Напишите простую функцию, которая будет возвращать качество модели на отложенной выборке, и обучите наш первый классификатор**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9, seed=17):\n",
    "    '''\n",
    "    X, y – выборка\n",
    "    ratio – в каком отношении поделить выборку\n",
    "    C, seed – коэф-т регуляризации и random_state \n",
    "              логистической регрессии\n",
    "    '''\n",
    "    \n",
    "    x_train_len = int(ratio * X.shape[0])\n",
    "    X_train = X[: x_train_len, :]\n",
    "    X_test = X[x_train_len :, :]\n",
    "    \n",
    "    Y_train = y[: x_train_len]\n",
    "    Y_test = y[x_train_len :]\n",
    "    \n",
    "#     logit = LogisticRegression(n_jobs=-1, C=C, random_state=seed, solver='lbfgs')\n",
    "    logit = LogisticRegression(n_jobs=-1, C=C, random_state=seed, solver='liblinear')\n",
    "    \n",
    "    logit.fit(X_train, Y_train)\n",
    "    \n",
    "    pred_valid = logit.predict_proba(X_test)[:, 1]\n",
    "    return roc_auc_score(Y_test, pred_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заведём функцию для проверки числа правильных ответов (как в уроке по Decision tree)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_value(X, y, C=1.0, ratio = 0.7, seed=17):\n",
    "    '''\n",
    "    X, y – выборка\n",
    "    ratio – в каком отношении поделить выборку\n",
    "    C, seed – коэф-т регуляризации и random_state \n",
    "              логистической регрессии\n",
    "    '''\n",
    "    \n",
    "    x_train_len = int(ratio * X.shape[0])\n",
    "    X_train = X[: x_train_len, :]\n",
    "    X_test = X[x_train_len :, :]\n",
    "    \n",
    "    Y_train = y[: x_train_len]\n",
    "    Y_test = y[x_train_len :]\n",
    "    \n",
    "    logit = LogisticRegression(n_jobs=-1, C=C, random_state=seed, solver='lbfgs')\n",
    "    \n",
    "    logit.fit(X_train, Y_train)\n",
    "    \n",
    "    pred = logit.predict(X_test)\n",
    "    \n",
    "    return accuracy_score(Y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрите, какой получился ROC AUC на отложенной выборке.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9197955574958127"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X=X_train_sparse, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать эту модель нашей первой отправной точкой (baseline). Для построения модели для прогноза на тестовой выборке **необходимо обучить модель заново уже на всей обучающей выборке** (пока наша модель обучалась лишь на части данных), что повысит ее обобщающую способность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для записи прогнозов в файл\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель на всей выборке, сделайте прогноз для тестовой выборки и сделайте посылку в соревновании**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2', random_state=17,\n",
       "                   solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(n_jobs=-1, C=1, random_state=17, solver='lbfgs')\n",
    "logit.fit(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.21954270e-03, 2.51892726e-09, 6.16010896e-09, ...,\n",
       "       8.43147766e-03, 3.87735238e-04, 1.29530564e-05])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probabilities = logit.predict_proba(X_test_sparse)\n",
    "pred_probabilities[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series = pd.Series(data=pred_probabilities[:, 1], index=range(1, pred_probabilities.shape[0] + 1))\n",
    "# series.to_csv(path_or_buf=\"../../data/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/benchmark_1.csv\",\n",
    "#               header=[\"target\"],\n",
    "#               index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы выполните эти действия и загрузите ответ на [странице](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнования, то воспроизведете первый бенчмарк \"Logit\".\n",
    "\n",
    "### 3. Улучшение модели, построение новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте такой признак, который будет представлять собой число вида ГГГГММ от той даты, когда проходила сессия, например 201407 -- 2014 год и 7 месяц. Таким образом, мы будем учитывать помесячный [линейный тренд](http://people.duke.edu/~rnau/411trend.htm) за весь период предоставленных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_features = pd.DataFrame(index=train_df.index)\n",
    "new_test_features = pd.DataFrame(index=test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 0), (82797, 0))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_features.shape, new_test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 253561 entries, 21669 to 204762\n",
      "Data columns (total 21 columns):\n",
      "site1     253561 non-null int64\n",
      "time1     253561 non-null datetime64[ns]\n",
      "site2     253561 non-null int64\n",
      "time2     250098 non-null datetime64[ns]\n",
      "site3     253561 non-null int64\n",
      "time3     246919 non-null datetime64[ns]\n",
      "site4     253561 non-null int64\n",
      "time4     244321 non-null datetime64[ns]\n",
      "site5     253561 non-null int64\n",
      "time5     241829 non-null datetime64[ns]\n",
      "site6     253561 non-null int64\n",
      "time6     239495 non-null datetime64[ns]\n",
      "site7     253561 non-null int64\n",
      "time7     237297 non-null datetime64[ns]\n",
      "site8     253561 non-null int64\n",
      "time8     235224 non-null datetime64[ns]\n",
      "site9     253561 non-null int64\n",
      "time9     233084 non-null datetime64[ns]\n",
      "site10    253561 non-null int64\n",
      "time10    231052 non-null datetime64[ns]\n",
      "target    253561 non-null int64\n",
      "dtypes: datetime64[ns](10), int64(11)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ['time%d' % d for d in range(1, 11)]\n",
    "train_na_zero = train_df[time].fillna(value=pd.Timestamp(0), inplace=False)\n",
    "test_na_zero = test_df[time].fillna(value=pd.Timestamp(0), inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 253561 entries, 21669 to 204762\n",
      "Data columns (total 10 columns):\n",
      "time1     253561 non-null datetime64[ns]\n",
      "time2     253561 non-null datetime64[ns]\n",
      "time3     253561 non-null datetime64[ns]\n",
      "time4     253561 non-null datetime64[ns]\n",
      "time5     253561 non-null datetime64[ns]\n",
      "time6     253561 non-null datetime64[ns]\n",
      "time7     253561 non-null datetime64[ns]\n",
      "time8     253561 non-null datetime64[ns]\n",
      "time9     253561 non-null datetime64[ns]\n",
      "time10    253561 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](10)\n",
      "memory usage: 21.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_na_zero.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year_month\n",
       "session_id           \n",
       "21669          201301\n",
       "54843          201301\n",
       "77292          201301\n",
       "114021         201301\n",
       "146670         201301"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Рассмотрим только время начала каждой сессии - поле time1\n",
    "new_train_features['year_month'] = train_na_zero['time1'].apply(lambda ts: str(ts.year * 100 + ts.month))\n",
    "new_test_features['year_month'] = test_na_zero['time1'].apply(lambda ts: str(ts.year * 100 + ts.month))\n",
    "\n",
    "new_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(new_train_features['year_month'].values.reshape(-1, 1))\n",
    "\n",
    "new_train_features['year_month_scaled'] = scaler.transform(new_train_features['year_month'].values.reshape(-1, 1))\n",
    "new_test_features['year_month_scaled'] = scaler.transform(new_test_features['year_month'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year_month_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year_month  year_month_scaled\n",
       "session_id                              \n",
       "21669          201301          -1.744405\n",
       "54843          201301          -1.744405\n",
       "77292          201301          -1.744405\n",
       "114021         201301          -1.744405\n",
       "146670         201301          -1.744405"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте новый признак, предварительно отмасштабировав его с помощью `StandardScaler`, и снова посчитайте ROC AUC на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48371), (253561, 48372))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Нужно объединить новые данные с существующими в разреженной матрице X_train_sparse\n",
    "# Делаем это с помощью функции hstack из библиотеки scipy.sparse\n",
    "# Требуется дополнительное явное преобразование в csr_matrix\n",
    "X_train_sparse_new = csr_matrix(hstack([X_train_sparse,\n",
    "                                new_train_features['year_month_scaled'].values.reshape(-1, 1)]))\n",
    "X_train_sparse_new.shape # (253561, 48372)\n",
    "\n",
    "# Аналогично для тестового набора\n",
    "X_test_sparse_new = hstack([X_test_sparse,\n",
    "                             new_test_features['year_month_scaled'].values.reshape(-1, 1)])\n",
    "X_test_sparse_new.shape # (82797, 48372)\n",
    "X_train_sparse.shape, X_train_sparse_new.shape # Добавился дополнительный признак в shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 313 ms, sys: 98.8 ms, total: 412 ms\n",
      "Wall time: 2.67 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9198902054055882"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_auc_lr_valid(X=X_train_sparse_new, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте два новых признака: start_hour и morning.**\n",
    "\n",
    "Признак `start_hour` – это час в который началась сессия (от 0 до 23), а бинарный признак `morning` равен 1, если сессия началась утром и 0, если сессия началась позже (будем считать, что утро это если `start_hour равен` 11 или меньше).\n",
    "\n",
    "**Посчитйте ROC AUC на отложенной выборке для выборки с:**\n",
    "- сайтами, `start_month` и `start_hour`\n",
    "- сайтами, `start_month` и `morning`\n",
    "- сайтами, `start_month`, `start_hour` и `morning`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_month + start_hour\n",
    "# Создадим похожую фичу для идентификации, в какое время суток предполагаемый человек начинает сессию\n",
    "new_train_features['start_hour'] = train_na_zero['time1'].apply(lambda ts: str(ts.hour))\n",
    "new_test_features['start_hour'] = test_na_zero['time1'].apply(lambda ts: str(ts.hour))\n",
    "\n",
    "# Фича с учётом года и месяца работает хуже\n",
    "# new_train_features['start_hour'] = train_na_zero['time1'].apply(lambda ts: str((ts.year * 100 + ts.month) * 100 + ts.hour))\n",
    "# new_test_features['start_hour'] = test_na_zero['time1'].apply(lambda ts: str((ts.year * 100 + ts.month) * 100 + ts.hour))\n",
    "\n",
    "# start_month + start_hour + morning\n",
    "# Аналогичную операцию проделаем для признака morning\n",
    "new_train_features['morning'] = train_na_zero['time1'].apply(lambda ts: int(ts.hour <= 11))\n",
    "new_test_features['morning'] = test_na_zero['time1'].apply(lambda ts: int(ts.hour <= 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(new_train_features['start_hour'].values.reshape(-1, 1))\n",
    "\n",
    "new_train_features['start_hour_scaled'] = scaler.transform(new_train_features['start_hour'].values.reshape(-1, 1))\n",
    "new_test_features['start_hour_scaled'] = scaler.transform(new_test_features['start_hour'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year_month_scaled</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>start_hour_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year_month  year_month_scaled start_hour  morning  \\\n",
       "session_id                                                     \n",
       "21669          201301          -1.744405          8        1   \n",
       "54843          201301          -1.744405          8        1   \n",
       "77292          201301          -1.744405          8        1   \n",
       "114021         201301          -1.744405          8        1   \n",
       "146670         201301          -1.744405          8        1   \n",
       "\n",
       "            start_hour_scaled  \n",
       "session_id                     \n",
       "21669               -1.357366  \n",
       "54843               -1.357366  \n",
       "77292               -1.357366  \n",
       "114021              -1.357366  \n",
       "146670              -1.357366  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year_month_scaled</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>start_hour_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201410</td>\n",
       "      <td>0.822948</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.407823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201407</td>\n",
       "      <td>0.752287</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.407823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201412</td>\n",
       "      <td>0.870055</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201411</td>\n",
       "      <td>0.846501</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.724338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201405</td>\n",
       "      <td>0.705179</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year_month  year_month_scaled start_hour  morning  \\\n",
       "session_id                                                     \n",
       "1              201410           0.822948         11        1   \n",
       "2              201407           0.752287         11        1   \n",
       "3              201412           0.870055         15        0   \n",
       "4              201411           0.846501         10        1   \n",
       "5              201405           0.705179         15        0   \n",
       "\n",
       "            start_hour_scaled  \n",
       "session_id                     \n",
       "1                   -0.407823  \n",
       "2                   -0.407823  \n",
       "3                    0.858234  \n",
       "4                   -0.724338  \n",
       "5                    0.858234  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48372), (253561, 48373))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Снова объединяем новые данные с существующими в разреженной матрице X_train_sparse_new\n",
    "# Делаем это с помощью функции hstack из библиотеки scipy.sparse\n",
    "# Требуется дополнительное явное преобразование в csr_matrix\n",
    "X_train_sparse_new_2 = csr_matrix(hstack([X_train_sparse_new,\n",
    "                                  new_train_features['start_hour_scaled'].values.reshape(-1, 1)]))\n",
    "\n",
    "# Аналогично для тестового набора\n",
    "X_test_sparse_new_2 = hstack([X_test_sparse_new,\n",
    "                             new_test_features['start_hour_scaled'].values.reshape(-1, 1)])\n",
    "X_train_sparse_new.shape, X_train_sparse_new_2.shape # Добавился дополнительный признак в shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 362 ms, sys: 95.2 ms, total: 457 ms\n",
      "Wall time: 2.75 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9573322845076919"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Проверяем качество с 2-мя признаками по ROC AUC\n",
    "get_auc_lr_valid(X=X_train_sparse_new_2, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48373), (253561, 48374))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавим в разреженную матрицу ещё одну фичу morning с помощью того же hstack\n",
    "X_train_sparse_new_3 = csr_matrix(hstack([X_train_sparse_new_2,\n",
    "                                  new_train_features['morning'].values.reshape(-1, 1)]))\n",
    "\n",
    "# Аналогично для тестового набора\n",
    "X_test_sparse_new_3 = hstack([X_test_sparse_new_2,\n",
    "                             new_test_features['morning'].values.reshape(-1, 1)])\n",
    "X_train_sparse_new_2.shape, X_train_sparse_new_3.shape # Добавился дополнительный признак в shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 360 ms, sys: 99.4 ms, total: 459 ms\n",
      "Wall time: 2.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9585507820000507"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Проверяем качество с 3-мя признаками по ROC AUC\n",
    "get_auc_lr_valid(X=X_train_sparse_new_3, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2', random_state=17,\n",
       "                   solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим новую модель\n",
    "\n",
    "logit = LogisticRegression(n_jobs=-1, C=1, random_state=17, solver='lbfgs')\n",
    "logit.fit(X_train_sparse_new_3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.26264685e-05, 6.26559747e-08, 2.43439679e-09, ...,\n",
       "       2.04955019e-04, 6.29702900e-06, 2.71673195e-07])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим файл посылки для Kaggle с учётом 3-х новых фич\n",
    "# Предсказанные результаты\n",
    "pred_probabilities_3 = logit.predict_proba(X_test_sparse_new_3)\n",
    "pred_probabilities_3[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_to_submission_file(pred_probabilities_3[:, 1],\n",
    "#                          out_file = \"../../data/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/benchmark_1_5.csv\",\n",
    "#                          target='target',\n",
    "#                          index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Подбор коэффицициента регуляризации\n",
    "\n",
    "Итак, мы ввели признаки, которые улучшают качество нашей модели по сравнению с первым бейслайном. Можем ли мы добиться большего значения метрики? После того, как мы сформировали обучающую и тестовую выборки, почти всегда имеет смысл подобрать оптимальные гиперпараметры -- характеристики модели, которые не изменяются во время обучения. Например, на 3 неделе вы проходили решающие деревья, глубина дерева это гиперпараметр, а признак, по которому происходит ветвление и его значение -- нет. В используемой нами логистической регрессии веса каждого признака изменяются и во время обучения находится их оптимальные значения, а коэффициент регуляризации остается постоянным. Это тот гиперпараметр, который мы сейчас будем оптимизировать.\n",
    "\n",
    "Посчитайте качество на отложенной выборке с коэффициентом регуляризации, который по умолчанию `C=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.4 ms, sys: 66 ms, total: 131 ms\n",
      "Wall time: 2.42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9908372661662438"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# наша целевая переменная на отложенной выборке (для тестирования)\n",
    "get_accuracy_value(X=X_train_sparse_new_3, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 68.5 ms, sys: 74.4 ms, total: 143 ms\n",
      "Wall time: 2.87 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9585507820000507"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Проверяем качество с 3-мя признаками по ROC AUC - так проверяется на Kaggle\n",
    "get_auc_lr_valid(X=X_train_sparse_new_3, y=y_train, C=1, ratio=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постараемся побить этот результат за счет оптимизации коэффициента регуляризации. Возьмем набор возможных значений C и для каждого из них посчитаем значение метрики на отложенной выборке.\n",
    "\n",
    "Найдите `C` из `np.logspace(-3, 1, 10)`, при котором ROC AUC на отложенной выборке максимален. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.960868674591127, 0.1668100537200059)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_coefficient = np.logspace(-3, 1, 10)\n",
    "\n",
    "result = (0, 0)\n",
    "for c in reg_coefficient:\n",
    "    local_result = get_auc_lr_valid(X=X_train_sparse_new_3, ratio=0.9, y=y_train, C=c)\n",
    "    if result[0] < local_result:\n",
    "        result = (local_result, c)\n",
    "\n",
    "result_reg_coefficient = result[1]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, обучите модель с найденным оптимальным значением коэффициента регуляризации и с построенными признаками `start_hour`, `start_month` и `morning`. Если вы все сделали правильно и загрузите это решение, то повторите второй бенчмарк соревнования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.54857950e-04, 2.35772047e-06, 9.26844124e-07, ...,\n",
       "       5.60875922e-04, 6.04939606e-05, 7.53602794e-06])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим файл посылки для Kaggle с учётом 3-х новых фич и коэффициента регуляризации\n",
    "# Предсказанные результаты\n",
    "logit = LogisticRegression(n_jobs=-1, C=result_reg_coefficient, random_state=17, solver='lbfgs')\n",
    "logit.fit(X_train_sparse_new_3, y_train)\n",
    "\n",
    "pred_probabilities_2_nd_benchmark = logit.predict_proba(X_test_sparse_new_3)\n",
    "pred_probabilities_2_nd_benchmark[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_to_submission_file(pred_probabilities_2_nd_benchmark[:, 1],\n",
    "#                          out_file = \"../../data/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/benchmark_2.csv\",\n",
    "#                          target='target',\n",
    "#                          index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. А теперь попробуем подобрать ещё несколько фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year_month_scaled</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>start_hour_scaled</th>\n",
       "      <th>sites_amount_per_session</th>\n",
       "      <th>short_session</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year_month  year_month_scaled start_hour  morning  \\\n",
       "session_id                                                     \n",
       "21669          201301          -1.744405          8        1   \n",
       "54843          201301          -1.744405          8        1   \n",
       "77292          201301          -1.744405          8        1   \n",
       "114021         201301          -1.744405          8        1   \n",
       "146670         201301          -1.744405          8        1   \n",
       "\n",
       "            start_hour_scaled  sites_amount_per_session  short_session  \n",
       "session_id                                                              \n",
       "21669               -1.357366                         2              1  \n",
       "54843               -1.357366                         4              1  \n",
       "77292               -1.357366                        10              0  \n",
       "114021              -1.357366                        10              0  \n",
       "146670              -1.357366                        10              0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Попробуем добавить фичу с количеством сайтов, просматриваемых за одну сессию sites_amount_per_session\n",
    "\n",
    "amount_of_unique_sites_train = X_train_sparse.sum(axis=1)\n",
    "amount_of_unique_sites_test = X_test_sparse.sum(axis=1)\n",
    "\n",
    "new_train_features['sites_amount_per_session'] = amount_of_unique_sites_train\n",
    "new_test_features['sites_amount_per_session'] = amount_of_unique_sites_test\n",
    "\n",
    "new_train_features['short_session'] = amount_of_unique_sites_train < 10\n",
    "new_test_features['short_session'] = amount_of_unique_sites_test < 10\n",
    "\n",
    "new_train_features['short_session'] = new_train_features['short_session'].astype('int')\n",
    "new_test_features['short_session'] = new_test_features['short_session'].astype('int')\n",
    "new_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year_month_scaled</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>start_hour_scaled</th>\n",
       "      <th>sites_amount_per_session</th>\n",
       "      <th>short_session</th>\n",
       "      <th>sites_amount_per_session_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.328969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.177031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year_month  year_month_scaled start_hour  morning  \\\n",
       "session_id                                                     \n",
       "21669          201301          -1.744405          8        1   \n",
       "54843          201301          -1.744405          8        1   \n",
       "77292          201301          -1.744405          8        1   \n",
       "114021         201301          -1.744405          8        1   \n",
       "146670         201301          -1.744405          8        1   \n",
       "\n",
       "            start_hour_scaled  sites_amount_per_session  short_session  \\\n",
       "session_id                                                               \n",
       "21669               -1.357366                         2              1   \n",
       "54843               -1.357366                         4              1   \n",
       "77292               -1.357366                        10              0   \n",
       "114021              -1.357366                        10              0   \n",
       "146670              -1.357366                        10              0   \n",
       "\n",
       "            sites_amount_per_session_scaled  \n",
       "session_id                                   \n",
       "21669                             -4.328969  \n",
       "54843                             -3.177031  \n",
       "77292                              0.278784  \n",
       "114021                             0.278784  \n",
       "146670                             0.278784  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_5 = StandardScaler()\n",
    "scaler_5.fit(new_train_features['sites_amount_per_session'].values.reshape(-1, 1))\n",
    "\n",
    "new_train_features['sites_amount_per_session_scaled'] = scaler_5.transform(new_train_features['sites_amount_per_session'].values.reshape(-1, 1))\n",
    "new_test_features['sites_amount_per_session_scaled'] = scaler_5.transform(new_test_features['sites_amount_per_session'].values.reshape(-1, 1)) \n",
    "new_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48374), (253561, 48376))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавим в разреженную матрицу ещё одну фичу morning с помощью того же hstack\n",
    "X_train_sparse_new_4 = csr_matrix(hstack([X_train_sparse_new_3,\n",
    "                                  new_train_features[['sites_amount_per_session_scaled', 'short_session']].values]))\n",
    "\n",
    "# Аналогично для тестового набора\n",
    "X_test_sparse_new_4 = hstack([X_test_sparse_new_3,\n",
    "                             new_test_features[['sites_amount_per_session_scaled', 'short_session']].values])\n",
    "X_train_sparse_new_3.shape, X_train_sparse_new_4.shape # Добавились дополнительные признаки в shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 375 ms, sys: 103 ms, total: 478 ms\n",
      "Wall time: 2.84 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9617147695421517"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Проверяем качество с 3-мя признаками по ROC AUC - так проверяется на Kaggle\n",
    "get_auc_lr_valid(X=X_train_sparse_new_4, y=y_train, C=result_reg_coefficient, ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9620494336824589, 0.05994842503189409)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1 = (0, 0)\n",
    "for c in reg_coefficient:\n",
    "    local_result = get_auc_lr_valid(X=X_train_sparse_new_4, ratio=0.9, y=y_train, C=c)\n",
    "    if result_1[0] < local_result:\n",
    "        result_1 = (local_result, c)\n",
    "\n",
    "result_reg_coefficient_1 = result_1[1]\n",
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.6 ms, sys: 73.7 ms, total: 148 ms\n",
      "Wall time: 2.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9620494336824589"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Проверяем качество с 3-мя признаками по ROC AUC - так проверяется на Kaggle\n",
    "get_auc_lr_valid(X=X_train_sparse_new_4, y=y_train, C=result_reg_coefficient_1, ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.06128982e-04, 1.03396300e-05, 1.31627787e-05, ...,\n",
       "       9.07472535e-04, 1.53460865e-04, 3.15474427e-05])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(n_jobs=-1, C=result_reg_coefficient_1, random_state=17, solver='lbfgs')\n",
    "logit.fit(X_train_sparse_new_4, y_train)\n",
    "\n",
    "pred_probabilities_benchmark_2_1 = logit.predict_proba(X_test_sparse_new_4)\n",
    "pred_probabilities_benchmark_2_1[:, 1]\n",
    "\n",
    "# write_to_submission_file(pred_probabilities_benchmark_2_1[:, 1],\n",
    "#                          out_file = \"../../data/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/benchmark_2_1.csv\",\n",
    "#                          target='target',\n",
    "#                          index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_zero_na_df = train_na_zero.copy(deep=True)\n",
    "new_test_zero_na_df = train_na_zero.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time1</th>\n",
       "      <th>time2</th>\n",
       "      <th>time3</th>\n",
       "      <th>time4</th>\n",
       "      <th>time5</th>\n",
       "      <th>time6</th>\n",
       "      <th>time7</th>\n",
       "      <th>time8</th>\n",
       "      <th>time9</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>1970-01-01 00:00:00</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time1               time2               time3  \\\n",
       "session_id                                                               \n",
       "21669      2013-01-12 08:05:57 2013-01-12 08:05:57 1970-01-01 00:00:00   \n",
       "54843      2013-01-12 08:37:23 2013-01-12 08:37:23 2013-01-12 09:07:07   \n",
       "77292      2013-01-12 08:50:13 2013-01-12 08:50:14 2013-01-12 08:50:15   \n",
       "114021     2013-01-12 08:50:17 2013-01-12 08:50:17 2013-01-12 08:50:18   \n",
       "146670     2013-01-12 08:50:20 2013-01-12 08:50:20 2013-01-12 08:50:20   \n",
       "\n",
       "                         time4               time5               time6  \\\n",
       "session_id                                                               \n",
       "21669      1970-01-01 00:00:00 1970-01-01 00:00:00 1970-01-01 00:00:00   \n",
       "54843      2013-01-12 09:07:09 1970-01-01 00:00:00 1970-01-01 00:00:00   \n",
       "77292      2013-01-12 08:50:15 2013-01-12 08:50:16 2013-01-12 08:50:16   \n",
       "114021     2013-01-12 08:50:18 2013-01-12 08:50:18 2013-01-12 08:50:18   \n",
       "146670     2013-01-12 08:50:21 2013-01-12 08:50:21 2013-01-12 08:50:21   \n",
       "\n",
       "                         time7               time8               time9  \\\n",
       "session_id                                                               \n",
       "21669      1970-01-01 00:00:00 1970-01-01 00:00:00 1970-01-01 00:00:00   \n",
       "54843      1970-01-01 00:00:00 1970-01-01 00:00:00 1970-01-01 00:00:00   \n",
       "77292      2013-01-12 08:50:16 2013-01-12 08:50:16 2013-01-12 08:50:17   \n",
       "114021     2013-01-12 08:50:19 2013-01-12 08:50:19 2013-01-12 08:50:19   \n",
       "146670     2013-01-12 08:50:21 2013-01-12 08:50:22 2013-01-12 08:50:22   \n",
       "\n",
       "                        time10  \n",
       "session_id                      \n",
       "21669      2013-01-12 08:05:57  \n",
       "54843      2013-01-12 09:07:09  \n",
       "77292      2013-01-12 08:50:17  \n",
       "114021     2013-01-12 08:50:20  \n",
       "146670     2013-01-12 08:50:22  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(9, 0, -1):\n",
    "    intermediate_train_df = new_train_zero_na_df[(new_train_zero_na_df['time10'] == pd.Timestamp(0)) & \\\n",
    "                                                 (new_train_zero_na_df['time%s' % i] != pd.Timestamp(0))]\n",
    "    new_train_zero_na_df.loc[intermediate_train_df.index.values,\n",
    "                             ['time10']] = intermediate_train_df['time%s' % i]\n",
    "    \n",
    "    intermediate_test_df = new_test_zero_na_df[(new_test_zero_na_df['time10'] == pd.Timestamp(0)) & \\\n",
    "                                               (new_test_zero_na_df['time%s' % i] != pd.Timestamp(0))]\n",
    "    new_test_zero_na_df.loc[intermediate_test_df.index.values,\n",
    "                            ['time10']] = intermediate_test_df['time%s' % i]\n",
    "    \n",
    "new_train_zero_na_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year_month_scaled</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>start_hour_scaled</th>\n",
       "      <th>sites_amount_per_session</th>\n",
       "      <th>short_session</th>\n",
       "      <th>sites_amount_per_session_scaled</th>\n",
       "      <th>sites_open_time_frame</th>\n",
       "      <th>is_quick_launch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.328969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.177031</td>\n",
       "      <td>29.766667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278784</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278784</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278784</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year_month  year_month_scaled start_hour  morning  \\\n",
       "session_id                                                     \n",
       "21669          201301          -1.744405          8        1   \n",
       "54843          201301          -1.744405          8        1   \n",
       "77292          201301          -1.744405          8        1   \n",
       "114021         201301          -1.744405          8        1   \n",
       "146670         201301          -1.744405          8        1   \n",
       "\n",
       "            start_hour_scaled  sites_amount_per_session  short_session  \\\n",
       "session_id                                                               \n",
       "21669               -1.357366                         2              1   \n",
       "54843               -1.357366                         4              1   \n",
       "77292               -1.357366                        10              0   \n",
       "114021              -1.357366                        10              0   \n",
       "146670              -1.357366                        10              0   \n",
       "\n",
       "            sites_amount_per_session_scaled  sites_open_time_frame  \\\n",
       "session_id                                                           \n",
       "21669                             -4.328969               0.000000   \n",
       "54843                             -3.177031              29.766667   \n",
       "77292                              0.278784               0.066667   \n",
       "114021                             0.278784               0.050000   \n",
       "146670                             0.278784               0.033333   \n",
       "\n",
       "            is_quick_launch  \n",
       "session_id                   \n",
       "21669                     1  \n",
       "54843                     0  \n",
       "77292                     1  \n",
       "114021                    1  \n",
       "146670                    1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавляем новую фичу - is_quick_launch, которая показываеет, были ли открыти все сайты в сессии в течение 5 минут\n",
    "# или открывались один за другим в течение более долгого времени\n",
    "new_train_features['sites_open_time_frame'] = (new_train_zero_na_df['time10'] - \\\n",
    "                                               new_train_zero_na_df['time1']).apply(lambda dt: dt.total_seconds() / 60.0)\n",
    "\n",
    "new_test_features['sites_open_time_frame'] = (new_test_zero_na_df['time10'] - \\\n",
    "                                              new_test_zero_na_df['time1']).apply(lambda dt: dt.total_seconds() / 60.0)\n",
    "\n",
    "new_train_features['is_quick_launch'] = (new_train_features['sites_open_time_frame'] < 2).astype(np.int)\n",
    "\n",
    "new_test_features['is_quick_launch'] = (new_test_features['sites_open_time_frame'] < 2).astype(np.int)\n",
    "\n",
    "new_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>year_month_scaled</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>morning</th>\n",
       "      <th>start_hour_scaled</th>\n",
       "      <th>sites_amount_per_session</th>\n",
       "      <th>short_session</th>\n",
       "      <th>sites_amount_per_session_scaled</th>\n",
       "      <th>sites_open_time_frame</th>\n",
       "      <th>is_quick_launch</th>\n",
       "      <th>sites_open_time_frame_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.328969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.468233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.177031</td>\n",
       "      <td>29.766667</td>\n",
       "      <td>0</td>\n",
       "      <td>5.570015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278784</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.454709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278784</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.458090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>201301</td>\n",
       "      <td>-1.744405</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.357366</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278784</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.461471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           year_month  year_month_scaled start_hour  morning  \\\n",
       "session_id                                                     \n",
       "21669          201301          -1.744405          8        1   \n",
       "54843          201301          -1.744405          8        1   \n",
       "77292          201301          -1.744405          8        1   \n",
       "114021         201301          -1.744405          8        1   \n",
       "146670         201301          -1.744405          8        1   \n",
       "\n",
       "            start_hour_scaled  sites_amount_per_session  short_session  \\\n",
       "session_id                                                               \n",
       "21669               -1.357366                         2              1   \n",
       "54843               -1.357366                         4              1   \n",
       "77292               -1.357366                        10              0   \n",
       "114021              -1.357366                        10              0   \n",
       "146670              -1.357366                        10              0   \n",
       "\n",
       "            sites_amount_per_session_scaled  sites_open_time_frame  \\\n",
       "session_id                                                           \n",
       "21669                             -4.328969               0.000000   \n",
       "54843                             -3.177031              29.766667   \n",
       "77292                              0.278784               0.066667   \n",
       "114021                             0.278784               0.050000   \n",
       "146670                             0.278784               0.033333   \n",
       "\n",
       "            is_quick_launch  sites_open_time_frame_scaled  \n",
       "session_id                                                 \n",
       "21669                     1                     -0.468233  \n",
       "54843                     0                      5.570015  \n",
       "77292                     1                     -0.454709  \n",
       "114021                    1                     -0.458090  \n",
       "146670                    1                     -0.461471  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_6 = StandardScaler()\n",
    "scaler_6.fit(new_train_features['sites_open_time_frame'].values.reshape(-1, 1))\n",
    "\n",
    "new_train_features['sites_open_time_frame_scaled'] = scaler_6.transform(new_train_features['sites_open_time_frame'].values.reshape(-1, 1))\n",
    "new_test_features['sites_open_time_frame_scaled'] = scaler_6.transform(new_test_features['sites_open_time_frame'].values.reshape(-1, 1)) \n",
    "new_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48376), (253561, 48377))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавим в разреженную матрицу ещё одну фичу is_quick_launch с помощью того же hstack\n",
    "X_train_sparse_new_5 = csr_matrix(hstack([X_train_sparse_new_4,\n",
    "                                  new_train_features[['is_quick_launch']].values]))\n",
    "\n",
    "# Аналогично для тестового набора\n",
    "X_test_sparse_new_5 = hstack([X_test_sparse_new_4,\n",
    "                             new_test_features[['is_quick_launch']].values])\n",
    "X_train_sparse_new_4.shape, X_train_sparse_new_5.shape # Добавились дополнительные признаки в shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9623047717038073, 0.05994842503189409)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2 = (0, 0)\n",
    "for c in reg_coefficient:\n",
    "    local_result = get_auc_lr_valid(X=X_train_sparse_new_5, ratio=0.9, y=y_train, C=c)\n",
    "    if result_2[0] < local_result:\n",
    "        result_2 = (local_result, c)\n",
    "\n",
    "result_reg_coefficient_2 = result_2[1]\n",
    "result_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 75.8 ms, sys: 77 ms, total: 153 ms\n",
      "Wall time: 2.52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9623047717038073"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Проверяем качество с 8-мью признаками по ROC AUC - так проверяется на Kaggle\n",
    "get_auc_lr_valid(X=X_train_sparse_new_5, y=y_train, C=result_reg_coefficient_2, ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.36124750e-04, 1.20388660e-05, 1.77178873e-05, ...,\n",
       "       9.53617329e-04, 1.69406166e-04, 2.55158060e-05])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(n_jobs=-1, C=result_reg_coefficient_2, random_state=17, solver='lbfgs')\n",
    "logit.fit(X_train_sparse_new_5, y_train)\n",
    "\n",
    "pred_probabilities_benchmark_2_1_1 = logit.predict_proba(X_test_sparse_new_5)\n",
    "pred_probabilities_benchmark_2_1_1[:, 1]\n",
    "\n",
    "# write_to_submission_file(pred_probabilities_benchmark_2_1_1[:, 1],\n",
    "#                          out_file = \"../../data/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/benchmark_2_1_1.csv\",\n",
    "#                          target='target',\n",
    "#                          index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Попробуем применить подход TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# табличка с индексами посещенных сайтов в сессии\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3725,   389, 15596, ...,     1,     5,     1]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разреженная матрица с мерами Term Frequency\n",
    "tf_csr_matrix = np.dot(full_sites_sparse, 1 / full_sites_sparse.shape[1])\n",
    "# print(tf_csr_matrix)\n",
    "\n",
    "# Вектор количества упомининий каждого сайта во всех сессиях\n",
    "overall_freq_vector = np.sum(full_sites_sparse > 0, axis=0)\n",
    "overall_freq_vector = np.array(overall_freq_vector)\n",
    "overall_freq_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x48371 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 48371 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим разреженную матрицу inverse document frequency:\n",
    "inverse_document_frequency_vector = np.log10(np.divide(full_sites_sparse.shape[0], overall_freq_vector))\n",
    "inverse_document_frequency_vector[inverse_document_frequency_vector == np.inf] = 0\n",
    "inverse_document_frequency_vector_csr = sci.sparse.csr_matrix(inverse_document_frequency_vector)\n",
    "inverse_document_frequency_vector_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse_document_frequency_matrix = sci.sparse.csr_matrix(np.diag(list(inverse_document_frequency_vector[0])))\n",
    "# inverse_document_frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<336358x48371 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1866898 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Матрица TF-IDF\n",
    "tf_idf_matrix_sparse = tf_csr_matrix.multiply(inverse_document_frequency_vector_csr)\n",
    "tf_idf_matrix_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48371), (253561,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse_tf_idf = tf_idf_matrix_sparse[:idx_split]\n",
    "X_test_sparse_tf_idf = tf_idf_matrix_sparse[idx_split:]\n",
    "X_train_sparse_tf_idf.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 54)\t2.6020656689760575e-05\n",
      "  (0, 55)\t2.7304207846449522e-05\n",
      "  (1, 54)\t5.204131337952115e-05\n",
      "  (1, 55)\t5.4608415692899044e-05\n",
      "  (2, 948)\t7.988348245434722e-05\n",
      "  (2, 783)\t3.70156695866675e-05\n",
      "  (2, 947)\t4.792872599372011e-05\n",
      "  (2, 944)\t7.458443424995822e-05\n",
      "  (2, 950)\t6.71486667740583e-05\n",
      "  (2, 945)\t0.0003250692273165672\n",
      "  (3, 946)\t6.869160817069894e-05\n",
      "  (3, 945)\t0.0001950415363899403\n",
      "  (3, 948)\t7.988348245434722e-05\n",
      "  (3, 947)\t9.585745198744022e-05\n",
      "  (3, 944)\t0.00022375330274987466\n",
      "  (4, 950)\t6.71486667740583e-05\n",
      "  (4, 945)\t0.00013002769092662687\n",
      "  (4, 951)\t7.950136495224857e-05\n",
      "  (4, 947)\t4.792872599372011e-05\n",
      "  (4, 949)\t0.0001593807820200155\n",
      "  (4, 946)\t0.00020607482451209683\n",
      "  (5, 954)\t7.811733754676568e-05\n",
      "  (5, 945)\t0.0001950415363899403\n",
      "  (5, 952)\t9.769268650998951e-05\n",
      "  (5, 946)\t0.00020607482451209683\n",
      "  :\t:\n",
      "  (253557, 3345)\t0.00010162593908741729\n",
      "  (253557, 49)\t3.491550343982676e-05\n",
      "  (253557, 51)\t2.306068331992799e-05\n",
      "  (253557, 752)\t9.286538765322759e-05\n",
      "  (253557, 4206)\t0.0001485312815628056\n",
      "  (253558, 3328)\t6.035324343648331e-05\n",
      "  (253558, 3593)\t6.773442267416239e-05\n",
      "  (253558, 7329)\t8.31417953559136e-05\n",
      "  (253558, 3323)\t5.04305328491145e-05\n",
      "  (253558, 978)\t5.17998896531158e-05\n",
      "  (253558, 783)\t7.4031339173335e-05\n",
      "  (253558, 3345)\t0.00010162593908741729\n",
      "  (253558, 51)\t2.306068331992799e-05\n",
      "  (253559, 3345)\t5.0812969543708644e-05\n",
      "  (253559, 3358)\t0.00011873491665127538\n",
      "  (253559, 752)\t4.6432693826613796e-05\n",
      "  (253559, 3412)\t6.037543975460912e-05\n",
      "  (253559, 3598)\t0.00012124658208866371\n",
      "  (253559, 3323)\t5.04305328491145e-05\n",
      "  (253559, 3327)\t0.00010307730117332668\n",
      "  (253560, 2890)\t5.330443438635137e-05\n",
      "  (253560, 54)\t2.6020656689760575e-05\n",
      "  (253560, 3358)\t5.936745832563769e-05\n",
      "  (253560, 3345)\t0.00015243890863112593\n",
      "  (253560, 221)\t3.56530880856243e-05\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sparse_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 107 ms, sys: 71.6 ms, total: 178 ms\n",
      "Wall time: 1.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.892248940003792"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_auc_lr_valid(X=X_train_sparse_tf_idf, ratio=0.9, y=y_train, C=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler(with_mean=False)\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "max_abs_scaler.fit(X_train_sparse_tf_idf)\n",
    "\n",
    "X_train_sparse_tf_idf_1 = max_abs_scaler.transform(X_train_sparse_tf_idf)\n",
    "X_test_sparse_tf_idf_1 = max_abs_scaler.transform(X_test_sparse_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 54)\t0.10000000000000002\n",
      "  (0, 55)\t0.3333333333333333\n",
      "  (1, 54)\t0.20000000000000004\n",
      "  (1, 55)\t0.6666666666666666\n",
      "  (2, 948)\t0.5\n",
      "  (2, 783)\t0.16666666666666669\n",
      "  (2, 947)\t0.16666666666666666\n",
      "  (2, 944)\t0.25\n",
      "  (2, 950)\t0.09999999999999998\n",
      "  (2, 945)\t0.49999999999999994\n",
      "  (3, 946)\t0.2\n",
      "  (3, 945)\t0.29999999999999993\n",
      "  (3, 948)\t0.5\n",
      "  (3, 947)\t0.3333333333333333\n",
      "  (3, 944)\t0.75\n",
      "  (4, 950)\t0.09999999999999998\n",
      "  (4, 945)\t0.19999999999999998\n",
      "  (4, 951)\t0.5\n",
      "  (4, 947)\t0.16666666666666666\n",
      "  (4, 949)\t0.5\n",
      "  (4, 946)\t0.6000000000000001\n",
      "  (5, 954)\t0.5\n",
      "  (5, 945)\t0.29999999999999993\n",
      "  (5, 952)\t0.2\n",
      "  (5, 946)\t0.6000000000000001\n",
      "  :\t:\n",
      "  (253557, 3345)\t0.2222222222222223\n",
      "  (253557, 49)\t0.19999999999999998\n",
      "  (253557, 51)\t0.09999999999999998\n",
      "  (253557, 752)\t0.6666666666666666\n",
      "  (253557, 4206)\t0.6666666666666666\n",
      "  (253558, 3328)\t0.33333333333333337\n",
      "  (253558, 3593)\t0.5\n",
      "  (253558, 7329)\t1.0\n",
      "  (253558, 3323)\t0.2\n",
      "  (253558, 978)\t0.25\n",
      "  (253558, 783)\t0.33333333333333337\n",
      "  (253558, 3345)\t0.2222222222222223\n",
      "  (253558, 51)\t0.09999999999999998\n",
      "  (253559, 3345)\t0.11111111111111115\n",
      "  (253559, 3358)\t0.2\n",
      "  (253559, 752)\t0.3333333333333333\n",
      "  (253559, 3412)\t0.25\n",
      "  (253559, 3598)\t0.3333333333333333\n",
      "  (253559, 3323)\t0.2\n",
      "  (253559, 3327)\t0.6666666666666666\n",
      "  (253560, 2890)\t0.5\n",
      "  (253560, 54)\t0.10000000000000002\n",
      "  (253560, 3358)\t0.1\n",
      "  (253560, 3345)\t0.3333333333333334\n",
      "  (253560, 221)\t0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# print(X_train_sparse_tf_idf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.7 ms, sys: 314 ms, total: 380 ms\n",
      "Wall time: 1.52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8929964622513341"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_auc_lr_valid(X=X_train_sparse_tf_idf_1, ratio=0.9, y=y_train, C=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 48371), (253561, 48377))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавим в разреженную матрицу tf-idf все фичи, что мы делали раньше с помощью того же hstack\n",
    "X_train_sparse_tf_idf_2 = csr_matrix(hstack([X_train_sparse_tf_idf_1,\n",
    "                                     new_train_features[['is_quick_launch',\n",
    "                                                         'sites_amount_per_session_scaled',\n",
    "                                                         'short_session',\n",
    "                                                         'start_hour_scaled',\n",
    "                                                         'morning',\n",
    "                                                         'year_month_scaled']].values]))\n",
    "\n",
    "# Аналогично для тестового набора\n",
    "X_test_sparse_tf_idf_2 = csr_matrix(hstack([X_test_sparse_tf_idf_1,\n",
    "                                    new_test_features[['is_quick_launch',\n",
    "                                                       'sites_amount_per_session_scaled',\n",
    "                                                       'short_session',\n",
    "                                                       'start_hour_scaled',\n",
    "                                                       'morning',\n",
    "                                                       'year_month_scaled']].values]))\n",
    "X_train_sparse_tf_idf_1.shape, X_train_sparse_tf_idf_2.shape # Добавились дополнительные признаки в shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9618295697580757, 1.2915496650148828)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_3 = (0, 0)\n",
    "for c in reg_coefficient:\n",
    "    local_result = get_auc_lr_valid(X=X_train_sparse_tf_idf_2, ratio=0.9, y=y_train, C=c)\n",
    "    if result_3[0] < local_result:\n",
    "        result_3 = (local_result, c)\n",
    "\n",
    "result_reg_coefficient_3 = result_3[1]\n",
    "result_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82797,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(n_jobs=-1, C=result_reg_coefficient_3, random_state=17, solver='lbfgs')\n",
    "logit.fit(X_train_sparse_tf_idf_2, y_train)\n",
    "\n",
    "pred_probabilities_benchmark_2_1_1_tf_idf = logit.predict_proba(X_test_sparse_tf_idf_2)\n",
    "pred_probabilities_benchmark_2_1_1_tf_idf[:, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(pred_probabilities_benchmark_2_1_1_tf_idf[:, 1],\n",
    "                         out_file = \"../../data/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/benchmark_2_1_1_tf_idf.csv\",\n",
    "                         target='target',\n",
    "                         index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем добавить фичи, связанные с временем суток (утро, день, вечер, ночь)\n",
    "# Таким образом попробуем дифференцировать пользователей на несколько категорий\n",
    "# Взято у yorko\n",
    "def add_time_features(df, X_sparse):\n",
    "    hour = df['time1'].apply(lambda ts: ts.hour)\n",
    "    morning = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "    day = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "    evening = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "    night = ((hour >= 0) & (hour <= 6)).astype('int')\n",
    "    X = hstack([X_sparse, morning.values.reshape(-1, 1), \n",
    "                day.values.reshape(-1, 1), evening.values.reshape(-1, 1), \n",
    "                night.values.reshape(-1, 1)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1, random_state=17, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_split = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 21s, sys: 6.46 s, total: 2min 27s\n",
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# hangs with n_jobs > 1, and locally this runs much faster\n",
    "cv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 1.77 s, total: 1min 28s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_sparse_new_6 = add_time_features(train_df.fillna(0), X_train)\n",
    "X_test_sparse_new_6 = add_time_features(test_df.fillna(0), X_test)\n",
    "\n",
    "X_train_sparse_new_6.shape, X_test_sparse_new_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 844 ms, sys: 142 ms, total: 986 ms\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# hangs with n_jobs > 1, and locally this runs much faster\n",
    "cv_scores = cross_val_score(logit, X_train_sparse_new_6, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.87652264, 0.75129589, 0.93062182, 0.97864183, 0.90399565,\n",
       "        0.9383148 , 0.96249244, 0.92731279, 0.94886477, 0.9404352 ]),\n",
       " 0.915849783443105)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим дополнительные фичи\n",
    "X_train_sparse_new_7 = csr_matrix(hstack([X_train_sparse_new_6,\n",
    "                                     new_train_features[[\n",
    "                                                         'is_quick_launch', # good idea\n",
    "#                                                          'short_session', # bad idea\n",
    "#                                                          'sites_amount_per_session_scaled', # bad idea\n",
    "#                                                          'start_hour_scaled', # bad idea\n",
    "                                                         'year_month_scaled'\n",
    "                                     ]].values]))\n",
    "\n",
    "# Аналогично для тестового набора\n",
    "X_test_sparse_new_7 = csr_matrix(hstack([X_test_sparse_new_6,\n",
    "                                    new_test_features[[\n",
    "                                                       'is_quick_launch', # good idea\n",
    "#                                                        'short_session', # bad idea\n",
    "#                                                        'sites_amount_per_session_scaled', # bad idea\n",
    "#                                                        'start_hour_scaled', # bad idea\n",
    "                                                       'year_month_scaled'\n",
    "                                    ]].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 50006), (82797, 50006))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse_new_7.shape, X_test_sparse_new_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.4 ms, sys: 129 ms, total: 223 ms\n",
      "Wall time: 21.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.88245795, 0.75922897, 0.94971744, 0.97923451, 0.90502538,\n",
       "        0.94129751, 0.96494157, 0.92797815, 0.95043858, 0.94133002]),\n",
       " 0.9201650083462501)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# hangs with n_jobs > 1, and locally this runs much faster\n",
    "cv_scores = cross_val_score(logit, X_train_sparse_new_7, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1)\n",
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we tune regularization parameter `C`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = np.logspace(-2, 2, 10)\n",
    "\n",
    "logit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': c_values},\n",
    "                                  scoring='roc_auc', n_jobs=-1, cv=time_split, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 884 ms, total: 17.6 s\n",
      "Wall time: 5min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=10),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=17, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': array([1.00000000e-02, 2.78255940e-02, 7.74263683e-02, 2.15443469e-01,\n",
       "       5.99484250e-01, 1.66810054e+00, 4.64158883e+00, 1.29154967e+01,\n",
       "       3.59381366e+01, 1.00000000e+02])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_grid_searcher.fit(X_train_sparse_new_7, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9223720808549573, {'C': 0.21544346900318834})"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher.best_score_, logit_grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred = logit_grid_searcher.predict_proba(X_test_sparse_new_7)[:, 1] #ROC AUC 0.9223720808549573\n",
    "write_to_submission_file(logit_test_pred,\n",
    "                         out_file = \"../../data/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/benchmark_2_3.csv\",\n",
    "                         target='target',\n",
    "                         index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ещё раз пробуем TF-IDF, но уже встроенный, сразу с оптимизацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.23 s, sys: 46.6 ms, total: 3.28 s\n",
      "Wall time: 2.33 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((253561, 41592), (82797, 41592))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tf_idf_vectoriver = TfidfVectorizer()\n",
    "with open('train_sessions_text.txt') as inp_train_file:\n",
    "    X_train_tf_idf = tf_idf_vectoriver.fit_transform(inp_train_file)\n",
    "with open('test_sessions_text.txt') as inp_test_file:\n",
    "    X_test_tf_idf = tf_idf_vectoriver.transform(inp_test_file)\n",
    "X_train_tf_idf.shape, X_test_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_tf_idf = LogisticRegression(C=1, random_state=17, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 83.1 ms, sys: 109 ms, total: 192 ms\n",
      "Wall time: 4.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.79738066, 0.66527936, 0.87207069, 0.93336481, 0.84811885,\n",
       "        0.88257794, 0.92296525, 0.86409586, 0.92640888, 0.91885051]),\n",
       " 0.863111282374818)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# hangs with n_jobs > 1, and locally this runs much faster\n",
    "tf_idf_scores = cross_val_score(logit_tf_idf,\n",
    "                                X_train_tf_idf,\n",
    "                                y_train,\n",
    "                                cv=time_split, \n",
    "                                scoring='roc_auc',\n",
    "                                n_jobs=-1)\n",
    "tf_idf_scores, tf_idf_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86.3 ms, sys: 124 ms, total: 211 ms\n",
      "Wall time: 4.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.75953502, 0.6187712 , 0.85340736, 0.92646867, 0.82223631,\n",
       "        0.86798529, 0.91439287, 0.87419429, 0.91275137, 0.9145681 ]),\n",
       " 0.8464310472287077)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Сравним значения с самодельным экземпляром TF-IDF vectorizer'а в матрице X_train_sparse_tf_idf_1\n",
    "# hangs with n_jobs > 1, and locally this runs much faster\n",
    "tf_idf_scores_test = cross_val_score(logit_tf_idf,\n",
    "                                X_train_sparse_tf_idf_1,\n",
    "                                y_train,\n",
    "                                cv=time_split, \n",
    "                                scoring='roc_auc',\n",
    "                                n_jobs=-1)\n",
    "tf_idf_scores_test, tf_idf_scores_test.mean()\n",
    "# Значение меньше, вероятно потому, что матрица была дополнительно нормализована, к примеру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 1.83 s, total: 1min 30s\n",
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((253561, 41596), (82797, 41596))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train_tf_idf_1 = add_time_features(train_df.fillna(0), X_train_tf_idf)\n",
    "X_test_tf_idf_1 = add_time_features(test_df.fillna(0), X_test_tf_idf)\n",
    "\n",
    "X_train_tf_idf_1.shape, X_test_tf_idf_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 390 ms, sys: 118 ms, total: 508 ms\n",
      "Wall time: 5.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.8671512 , 0.80556054, 0.92529226, 0.96421019, 0.91430846,\n",
       "        0.94855961, 0.94764803, 0.93213002, 0.9518587 , 0.94846402]),\n",
       " 0.9205183037748885)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# hangs with n_jobs > 1, and locally this runs much faster\n",
    "tf_idf_scores = cross_val_score(logit_tf_idf,\n",
    "                                X_train_tf_idf_1,\n",
    "                                y_train,\n",
    "                                cv=time_split, \n",
    "                                scoring='roc_auc',\n",
    "                                n_jobs=-1)\n",
    "tf_idf_scores, tf_idf_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим дополнительные фичи\n",
    "X_train_tf_idf_2 = csr_matrix(hstack([X_train_tf_idf_1,\n",
    "                                     new_train_features[[\n",
    "                                         'is_quick_launch',\n",
    "                                         'year_month_scaled'\n",
    "                                     ]].values]))\n",
    "\n",
    "# Аналогично для тестового набора\n",
    "X_test_tf_idf_2 = csr_matrix(hstack([X_test_tf_idf_1,\n",
    "                                    new_test_features[[\n",
    "                                         'is_quick_launch',\n",
    "                                         'year_month_scaled'\n",
    "                                    ]].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91.5 ms, sys: 120 ms, total: 212 ms\n",
      "Wall time: 6.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.86712327, 0.81176322, 0.94944271, 0.96540641, 0.91616295,\n",
       "        0.95040444, 0.95195513, 0.93446082, 0.95274383, 0.94995003]),\n",
       " 0.9249412808323381)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# hangs with n_jobs > 1, and locally this runs much faster\n",
    "tf_idf_scores = cross_val_score(logit_tf_idf,\n",
    "                                X_train_tf_idf_2,\n",
    "                                y_train,\n",
    "                                cv=time_split, \n",
    "                                scoring='roc_auc',\n",
    "                                n_jobs=-1)\n",
    "tf_idf_scores, tf_idf_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = np.logspace(-2, 2, 10)\n",
    "\n",
    "logit_grid_searcher_tf_idf = GridSearchCV(estimator=logit_tf_idf,\n",
    "                                          param_grid={'C': c_values},\n",
    "                                          scoring='roc_auc',\n",
    "                                          n_jobs=-1,\n",
    "                                          cv=time_split,\n",
    "                                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 682 ms, total: 12.1 s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=10),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=17, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': array([1.00000000e-02, 2.78255940e-02, 7.74263683e-02, 2.15443469e-01,\n",
       "       5.99484250e-01, 1.66810054e+00, 4.64158883e+00, 1.29154967e+01,\n",
       "       3.59381366e+01, 1.00000000e+02])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_grid_searcher_tf_idf.fit(X_train_tf_idf_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9268835730331638, {'C': 4.6415888336127775})"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher_tf_idf.best_score_, logit_grid_searcher_tf_idf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_pred_tf_idf = logit_grid_searcher_tf_idf.predict_proba(X_test_tf_idf_2)[:, 1] #ROC AUC 0.9268835730331638\n",
    "write_to_submission_file(logit_test_pred_tf_idf,\n",
    "                         out_file = \"../../data/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2/benchmark_2_4_tf_idf.csv\",\n",
    "                         target='target',\n",
    "                         index_label=\"session_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
